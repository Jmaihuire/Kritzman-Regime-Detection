{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regime Detection Using Economic Variables\n",
    "\n",
    "Renjie Pan (renjie.pan@nyu.edu)\n",
    "\n",
    "Tianyu Zhang (tianyuzhang@nyu.edu)\n",
    "\n",
    "Liang Zou (liazou@nyu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Economic factors usually lead to regime shifts in financial markets. In this project, we try to develop a two-state Hidden Markov Model (HMM) to detect the regime given time series economic data (financial turbulence, economic growth, and inflation) based on the article \"Regime Shifts: Implications for Dynamic Strategies\" (Kritzman, Page, Turkington, 2012). We will first compute equity turbulence and currency turbulence from S&P 500 sector indices and currencies versus U.S. dollar respectively. After that, we perform exploratory data analysis (EDA) on these time series and conduct data cleansing (trimming) to remove anomaly points. At the end, we use HMM to generate two regimes for each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description and Loading\n",
    "\n",
    "The economic variables we will use are the following, where data were collected from Federal Reserve Economic Data (FRED) website:\n",
    "\n",
    "$\\textbf{Economic Growth}$: Quarter-over-quarter percentage change in seasonally adjusted U.S. real gross national product (GNP) from second quarter 1947 to fourth quarter 2009.\n",
    "\n",
    "$\\textbf{Inflation}$: Monthly percentage changes in seasonally adjuested US. Consumer Price Index (CPI) for all urban consumers from February 1947 to December 2009.\n",
    "\n",
    "$\\textbf{Sector Levels}$: 10 S&P 500 sector indices between December 1975 and December 2009.\n",
    "\n",
    "$\\textbf{Currency Pairs}$: G-10 currencies between December 1977 and December 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/liangzou/Desktop/Project-and-Presentation-Fall-2019/BNP Project/'\n",
    "data_file_name = 'kritzman data.xlsx'\n",
    "\n",
    "econ_growth = pd.read_excel(directory + data_file_name, 0)\n",
    "inflation = pd.read_excel(directory + data_file_name, 1)\n",
    "sector = pd.read_excel(directory + data_file_name, 2)\n",
    "currency = pd.read_excel(directory + data_file_name, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Financial Turbulence\n",
    "\n",
    "We compute the financial turbulence using the following:\n",
    "\n",
    "$$d_t = (y_t - \\mu) \\Sigma^{-1} (y_t - \\mu)'$$\n",
    "\n",
    "$y_t$: asset returns for period t\n",
    "\n",
    "$\\mu$: sample average historical returns\n",
    "\n",
    "$\\Sigma$: sample covariance matrix of historical returns\n",
    "\n",
    "$\\textbf{Equity Turbulence}$: Historical returns for past 10 years for S&P 500 sector indices\n",
    "\n",
    "$\\textbf{Currency Turbulence}$: Historical returns for past 3 years for G-10 currencies versus U.S. dollar (USD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_turbulence(df, years=3, alpha=0.01):\n",
    "    '''\n",
    "    Compute financial turbulence given time series data\n",
    "        input: \n",
    "            df || DataFrame || a Dataframe includes Column \"Date\"\n",
    "            years || integer || number of years to compute historical returns\n",
    "            alpha || float || a punishment coefficient when inverse-coveriance is singular\n",
    "        output: Turbulence || DataFrame || Column = [\"Date\", \"Turbulence\"]\n",
    "    '''\n",
    "    \n",
    "    # Compute return for this series\n",
    "    df_return = df.iloc[1:,1:].values / df.iloc[:-1,1:].values - 1\n",
    "    distance = []\n",
    "    error = []\n",
    "    days_in_year = 252\n",
    "    \n",
    "    for i in range(years * days_in_year, len(df)-1):\n",
    "        df_past_return = df_return[:i+1,:]\n",
    "        # Compute historical mean return\n",
    "        mu = np.mean(df_past_return, axis=0)\n",
    "        try:\n",
    "            # Compute inverse covariance matrix\n",
    "            inv_sig = np.linalg.inv(np.cov(df_past_return.T))\n",
    "        except:\n",
    "            # Find days when covariance matrices are not invertible\n",
    "            # and add small numbers to the diagonal\n",
    "            sigma = np.cov(df_past_return.T)\n",
    "            x = np.ones(sigma.shape[0])\n",
    "            inv_sig = np.linalg.inv(sigma + np.diag(x)*alpha)\n",
    "            error.append(i)\n",
    "\n",
    "        y = np.array(df_return[i,:])\n",
    "        d = np.dot(np.dot(y-mu, inv_sig),(y-mu).T)\n",
    "        distance.append(d)\n",
    "\n",
    "    Turbulence = pd.DataFrame({'Date': df['Date'][-len(distance):], 'Turbulence': distance})\n",
    "    \n",
    "    if error != []:\n",
    "        print('Rows that produce singular covariance matrix')\n",
    "        print(np.array(error) + 2)\n",
    "    \n",
    "    return Turbulence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_turbulence = compute_turbulence(sector, years=10)\n",
    "currency_turbulence = compute_turbulence(currency, years=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis and Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Economic Growth</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Equity Turbulence</th>\n",
       "      <th>Currency Turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>289.0000</td>\n",
       "      <td>870.0000</td>\n",
       "      <td>4905.0000</td>\n",
       "      <td>6669.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.2128</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>10.6787</td>\n",
       "      <td>7.9320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.8463</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>18.0354</td>\n",
       "      <td>27.8651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.0000</td>\n",
       "      <td>-1.8000</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.2000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>2.9631</td>\n",
       "      <td>2.7772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>5.2398</td>\n",
       "      <td>4.8709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.1000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>10.6382</td>\n",
       "      <td>8.7553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.7000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>393.9824</td>\n",
       "      <td>2072.4420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Economic Growth  Inflation  Equity Turbulence  Currency Turbulence\n",
       "count         289.0000   870.0000          4905.0000            6669.0000\n",
       "mean            3.2128     0.2847            10.6787               7.9320\n",
       "std             3.8463     0.3443            18.0354              27.8651\n",
       "min           -10.0000    -1.8000             0.0023               0.1927\n",
       "25%             1.2000     0.1000             2.9631               2.7772\n",
       "50%             3.1000     0.2000             5.2398               4.8709\n",
       "75%             5.1000     0.4000            10.6382               8.7553\n",
       "max            16.7000     2.0000           393.9824            2072.4420"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDA_dataframe = pd.concat([econ_growth.describe(), inflation.describe(), \n",
    "           sector_turbulence.describe(), currency_turbulence.describe()], axis=1)\n",
    "EDA_dataframe.columns = ['Economic Growth','Inflation','Equity Turbulence','Currency Turbulence']\n",
    "EDA_dataframe.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>2072.44202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Turbulence\n",
       "6265 2015-01-15  2072.44202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currency_turbulence.loc[currency_turbulence.iloc[:,1] > 2000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive statistics show all 4 time series are right-skewed with larger mean than median. The skewness is extremely large in equity and currency turbulence since a number of observations are greater than 100 whereas the means are 10.67 in equity and 7.93 in currency. \n",
    "\n",
    "On January 15th, 2015, the currency turbulence is 2072, which resulted from special event: The Swiss National Bank abandoned cap on the Swiss franc’s exchange rate against the euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_series(s, q=0.001):\n",
    "    \"\"\"\"\n",
    "    This function returns the trimmed version of a Series.\n",
    "        input:\n",
    "            s | Series | Series before trimmed\n",
    "            q | float  | specific quantile to trim\n",
    "        output:\n",
    "            s | Series | Series after trimmed\n",
    "    \"\"\"\n",
    "    q = s.quantile([q, 1-q])\n",
    "    if isinstance(q, pd.Series) and len(q) == 2:\n",
    "        s[s < q.iloc[0]] = q.iloc[0]\n",
    "        s[s > q.iloc[1]] = q.iloc[1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "econ_growth.iloc[:,1] = winsorize_series(pd.Series(econ_growth.iloc[:,1]))\n",
    "inflation.iloc[:,1] = winsorize_series(pd.Series(inflation.iloc[:,1]))\n",
    "sector_turbulence.loc[:,'Turbulence'] = winsorize_series(pd.Series(sector_turbulence.loc[:,'Turbulence']))\n",
    "currency_turbulence.loc[:,'Turbulence'] = winsorize_series(pd.Series(currency_turbulence.loc[:,'Turbulence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the impact of anomaly points, we trim the time series with 0.1% - 99.9% quantile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM based on Baum-Welch Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_hmm(y, dim=2, max_iteration=1000, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Fit Hidden Markov Model based on Baum-Welch Algorithm.\n",
    "    Here, we assume each regime is normally distributed with certain mean and variance.\n",
    "    @y: Series (time series data)\n",
    "    @dim: integer (number of regimes or states)\n",
    "    @max_iteration: interger (maximum number of iterations)\n",
    "    @tolerance: float (tolerance for convergence)\n",
    "    @return: list (A: transition probability matrix, mu: mean of normal distribution,\n",
    "                    sigma: standard deviation of normal distribution, p: initial probability)\n",
    "    \"\"\"\n",
    "    \n",
    "    # random.seed(42)\n",
    "    T = len(y)\n",
    "    mu_y = np.mean(y)\n",
    "    sigma_y = np.std(y)\n",
    "    mu = [mu_y] * dim\n",
    "    sigma = [sigma_y] * dim\n",
    "    \n",
    "    for d in range(dim): \n",
    "        mu[d] += np.asscalar(np.random.randn(1, 1) * sigma_y)\n",
    "        # mu[d] += np.asscalar((0.1 * (d + 1))* sigma_y)\n",
    "    \n",
    "    # Initialize transition probability matrix and initial probability\n",
    "    A = np.ones((dim, dim)) / dim\n",
    "    p = np.ones((1, dim)) / dim\n",
    "    PI = math.pi\n",
    "    \n",
    "    iteration = 1\n",
    "    likelihood = [-2**31]\n",
    "    change_likelihood = 2**31\n",
    "    \n",
    "    # Initialize matrices\n",
    "    B = np.zeros((T, dim))\n",
    "    forward = np.zeros((T, dim))\n",
    "    backward = np.zeros((T, dim))\n",
    "    scale = np.zeros((T, dim))\n",
    "    smoothed = np.zeros((T, dim))\n",
    "    xi = np.zeros((dim, dim, T))\n",
    "    \n",
    "    while change_likelihood > tolerance and iteration < max_iteration:\n",
    "        \n",
    "        for t in range(T):\n",
    "            for d in range(dim):\n",
    "                # Compute normal pdf for each time step, each regime\n",
    "                B[t,d] = np.asscalar(1 / np.sqrt(2 * PI * sigma[d]**2) * np.exp(-0.5 * ((y[t] - mu[d])/sigma[d])**2))\n",
    "        \n",
    "        forward[0,:] = p * B[0,:]\n",
    "        scale[0,:] = np.sum(forward[0,:])\n",
    "        forward[0,:] = forward[0,:] / np.sum(forward[0,:])\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            forward[t,:] = np.dot(forward[t-1,:], A)*B[t,:]\n",
    "            scale[t,:] = np.sum(forward[t,:])\n",
    "            forward[t,:] = forward[t,:] / np.sum(forward[t,:])\n",
    "            \n",
    "        backward[T-1,:] = B[T-1,:]\n",
    "        backward[T-1,:] = backward[T-1,:] / np.sum(backward[T-1,:])\n",
    "        \n",
    "        for t in range(T-2, -1 ,-1):\n",
    "            backward[t,:] = np.dot(A, backward[t+1,:].T).T*B[t+1,:]\n",
    "            backward[t,:] = backward[t,:] / np.sum(backward[t,:])\n",
    "            \n",
    "        for t in range(T):\n",
    "            smoothed[t,:] = forward[t,:]*backward[t,:]\n",
    "            smoothed[t,:] = smoothed[t,:] / np.sum(smoothed[t,:])\n",
    "            \n",
    "        for t in range(T-1):\n",
    "            xi[:,:,t] = A * np.dot(forward[t,:].reshape((dim, 1)), (backward[t+1,:]*B[t+1,:]).reshape((1, dim)))\n",
    "            xi[:,:,t] = xi[:,:,t] / np.sum(xi[:,:,t])\n",
    "                \n",
    "        p = smoothed[0,:]\n",
    "        exp_num_transitions = np.sum(xi, axis = 2)\n",
    "        \n",
    "        for d in range(dim):\n",
    "            A[d,:] = exp_num_transitions[d,:] / np.sum(xi[d,:,:])\n",
    "            mu[d] = np.asscalar(np.dot(smoothed[:,d].T,y).T / np.sum(smoothed[:,d]))   \n",
    "            sigma[d] = np.asscalar(np.sqrt(np.sum(smoothed[:,d]*(y-mu[d])*(y-mu[d])) / np.sum(smoothed[:,d])))\n",
    "            \n",
    "        likelihood.append(np.asscalar(np.sum(np.log(scale))))\n",
    "        change_likelihood = np.asscalar(np.abs(likelihood[-1]-likelihood[-2]))\n",
    "        iteration +=1\n",
    "    \n",
    "    print('Transition Probability =')\n",
    "    print(np.round(A, 4))\n",
    "    \n",
    "    print('Mean =')\n",
    "    print(np.round(mu, 4))\n",
    "    \n",
    "    print('Standard Deviation =')\n",
    "    print(np.round(sigma, 4))\n",
    "    \n",
    "    print('Initial Probability =')\n",
    "    print(np.round(p, 4))\n",
    "    \n",
    "    return [A, mu, sigma, p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Detection on Economic Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probability =\n",
      "[[0.9738 0.0262]\n",
      " [0.0203 0.9797]]\n",
      "Mean =\n",
      "[3.4483 2.9489]\n",
      "Standard Deviation =\n",
      "[4.9376 1.8956]\n",
      "Initial Probability =\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "econ_hmm = fit_hmm(econ_growth.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on economic growth time series, the two regimes are normally distributed with mean 3.45, 2.95 and standard deviation 4.94, 1.90 respectively. The result shows the center of two regimes are close to each other but the first one is more volatile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Detection on Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probability =\n",
      "[[0.9869 0.0131]\n",
      " [0.0458 0.9542]]\n",
      "Mean =\n",
      "[0.2035 0.5433]\n",
      "Standard Deviation =\n",
      "[0.2002 0.512 ]\n",
      "Initial Probability =\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "inflation_hmm = fit_hmm(inflation.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of inflation, the first regime has mean 0.20 with standard deviation 0.20 while the second one produces a normal distribution with mean 0.54 and standard deviation 0.51. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Detection on Equity turbulence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probability =\n",
      "[[0.8917 0.1083]\n",
      " [0.0409 0.9591]]\n",
      "Mean =\n",
      "[27.8203  4.881 ]\n",
      "Standard Deviation =\n",
      "[26.35    3.2517]\n",
      "Initial Probability =\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "sector_hmm = fit_hmm(sector_turbulence.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two regimes in equity turbulence are distinct to each other. The first one has mean 27.82 with standard deviation 26.35 while the later one has mean 4.88 and standard deviation 3.25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime Detection on Currency turbulence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Probability =\n",
      "[[0.9296 0.0704]\n",
      " [0.4023 0.5977]]\n",
      "Mean =\n",
      "[ 5.3518 21.6884]\n",
      "Standard Deviation =\n",
      "[ 3.6799 23.3688]\n",
      "Initial Probability =\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "currency_hmm = fit_hmm(currency_turbulence.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to equity turbulence, the first regime in currency is normally distributed with mean 5.35 and standard deviation 3.67 while the second one has mean 21.69 and standard deviation 23.37. Their centers are volatilies are quite different than each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Questions\n",
    "\n",
    "### 1. What are the assumptions behind the model?\n",
    "\n",
    "(a) We assume there are only two regimes in total.\n",
    "\n",
    "(b) Each regime is normally distributed with certain mean and standard deviation.\n",
    "\n",
    "(c) Every regime is independent of each other (correlation is 0).\n",
    "\n",
    "### 2. What happens if they are not true?\n",
    "\n",
    "### 3. What potential weaknesses and limitations can you identify in this approach?\n",
    "\n",
    "(a) The algorithm is not robust to extremely large values (outlier). We previously ran our HMM without data cleansing. Some time series fail to converge and produce NaN due to these anomaly observations. In the future, we may consider using more advanced optimization algorithms that are robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "Kritzman, Mark, Sebastien Page, and David Turkington. \"Regime shifts: Implications for dynamic strategies (corrected).\" Financial Analysts Journal 68.3 (2012): 22-39.\n",
    "\n",
    "Blackstone, Brian. \"What Happened With the Swiss Franc?\" The Wall Street Journal (2015). Retrieved from https://blogs.wsj.com/briefly/2015/01/15/what-happened-with-the-swiss-franc-the-short-answer/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
